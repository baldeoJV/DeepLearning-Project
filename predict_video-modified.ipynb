{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7940cf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from keras.models import load_model\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4435e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Define paths based on CCDEPLRL_PROJECT structure\n",
    "BASE_PATH = 'CCDEPLRL_PROJECT'\n",
    "MODEL_PATH = os.path.join(BASE_PATH, 'model', 'violence_detection.h5')\n",
    "INPUT_PATH = os.path.join(BASE_PATH, 'input')\n",
    "OUTPUT_PATH = os.path.join(BASE_PATH, 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad13a2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def predict_video(video_path):\n",
    "    # Make sure output directory exists\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    \n",
    "    print(f\"Processing video: {os.path.basename(video_path)}\")\n",
    "    \n",
    "    # Load the model\n",
    "    print(\"Loading model...\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "    \n",
    "    # Initialize deque for prediction averaging\n",
    "    Q = deque(maxlen=128)\n",
    "    \n",
    "    # Open the video\n",
    "    vs = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = vs.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Initialize video writer\n",
    "    output_filename = os.path.join(OUTPUT_PATH, f\"processed_{os.path.basename(video_path)}\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    writer = cv2.VideoWriter(output_filename, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Process each frame\n",
    "    frame_count = 0\n",
    "    violence_frames = 0\n",
    "    \n",
    "    while True:\n",
    "        # Read the next frame\n",
    "        (grabbed, frame) = vs.read()\n",
    "        \n",
    "        # If no frame was grabbed, we've reached the end\n",
    "        if not grabbed:\n",
    "            break\n",
    "        \n",
    "        # Create a copy of the frame for output\n",
    "        output = frame.copy()\n",
    "        \n",
    "        # Preprocess the frame for prediction\n",
    "        processed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        processed_frame = cv2.resize(processed_frame, (128, 128)).astype(\"float32\")\n",
    "        processed_frame = processed_frame / 255.0\n",
    "        \n",
    "        # Make prediction\n",
    "        preds = model.predict(np.expand_dims(processed_frame, axis=0))[0]\n",
    "        Q.append(preds)\n",
    "        \n",
    "        # Average predictions over time for stability\n",
    "        results = np.array(Q).mean(axis=0)\n",
    "        \n",
    "        # Determine if frame shows violence (threshold > 0.5)\n",
    "        is_violence = (results > 0.5)[0]\n",
    "        \n",
    "        # Count violent frames\n",
    "        if is_violence:\n",
    "            violence_frames += 1\n",
    "        \n",
    "        # Set text color based on prediction\n",
    "        text_color = (0, 0, 255) if is_violence else (0, 255, 0)  # Red for violence, Green for non-violence\n",
    "        \n",
    "        # Display prediction on frame\n",
    "        text = \"Violence: {}\".format(is_violence)\n",
    "        cv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, text_color, 3)\n",
    "        \n",
    "        # Write the frame to output video\n",
    "        writer.write(output)\n",
    "        \n",
    "        # Show the frame (optional, comment out for batch processing)\n",
    "        # cv2.imshow(\"Processing\", output)\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #    break\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    # Calculate violence percentage\n",
    "    violence_percentage = (violence_frames / frame_count) * 100 if frame_count > 0 else 0\n",
    "    \n",
    "    # Release resources\n",
    "    print(f\"[INFO] Completed processing {os.path.basename(video_path)}\")\n",
    "    print(f\"Violence percentage: {violence_percentage:.2f}%\")\n",
    "    writer.release()\n",
    "    vs.release()\n",
    "    \n",
    "    return violence_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b2337",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def process_all_videos():\n",
    "    # Get all videos from input directory\n",
    "    video_files = []\n",
    "    for ext in ['*.mp4', '*.avi', '*.mov', '*.mkv']:\n",
    "        video_files.extend(glob.glob(os.path.join(INPUT_PATH, ext)))\n",
    "    \n",
    "    if not video_files:\n",
    "        print(\"No video files found in the input directory!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(video_files)} videos to process\")\n",
    "    \n",
    "    # Process each video\n",
    "    results = {}\n",
    "    for video_path in video_files:\n",
    "        video_name = os.path.basename(video_path)\n",
    "        violence_percentage = predict_video(video_path)\n",
    "        results[video_name] = violence_percentage\n",
    "    \n",
    "    # Write summary report\n",
    "    report_path = os.path.join(BASE_PATH, 'violence_detection_report.txt')\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"Violence Detection Summary Report\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(\"Video Name | Violence Percentage\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        \n",
    "        for video_name, percentage in results.items():\n",
    "            f.write(f\"{video_name} | {percentage:.2f}%\\n\")\n",
    "    \n",
    "    print(f\"Processing complete! Summary report saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef003bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Check if model exists\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"Error: Model not found at {MODEL_PATH}\")\n",
    "        print(\"Please run train.py first to create the model.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Create a command-line argument parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-v\", \"--video\", help=\"Path to a specific video (optional)\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Process single video if specified, otherwise process all videos in input folder\n",
    "    if args.video:\n",
    "        video_path = args.video\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Error: Video file not found at {video_path}\")\n",
    "            exit(1)\n",
    "        predict_video(video_path)\n",
    "    else:\n",
    "        process_all_videos()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
